{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOpaAkymbMsNB7z98fzl0od",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4m5mNc44dHC",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVi3DWY2OoSa",
        "colab_type": "code",
        "outputId": "a00c1564-1f38-43c6-9cdf-07bfaeaec0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pdb\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 6.2MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 204kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 256kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 266kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 276kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 296kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 307kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 327kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 337kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 348kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 358kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 368kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 378kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 389kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 399kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 409kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 430kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 440kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 450kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 460kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 471kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 481kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 491kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 501kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 512kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 522kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 532kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 542kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 552kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 563kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 573kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 583kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 593kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 604kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 614kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 624kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 634kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 645kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 655kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 665kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 675kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 686kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 696kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 706kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 716kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 727kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 737kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 747kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 757kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 768kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 778kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 788kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 798kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 808kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 819kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 829kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 839kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 849kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 860kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 870kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 880kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 890kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 901kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 911kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 921kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 931kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 942kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 952kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 962kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 972kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 983kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 993kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.0MB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.0MB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 6.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okZ3iyatVLre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\")\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "def save(fname, extension=\"pickle\"):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + fig_extension)\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def load(fname, extension='pickle'):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + fig_extension)\n",
        "    \n",
        "    with open(path, 'rb') as f:\n",
        "        item = pickle.load(f)\n",
        "\n",
        "    return item"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMT-pg-Zq3qY",
        "colab_type": "code",
        "outputId": "49750a30-18b2-4cf2-8bd1-d3fbc1f5454e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxtv1YLAO5LS",
        "colab_type": "code",
        "outputId": "9c9cc01e-8392-49cc-995b-1d52dd5e3993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "!pip install lyricsgenius\n",
        "import lyricsgenius\n",
        "\n",
        "API_TOKEN = '1OWmIr37ZuUI5hDXjN_FIXJlbZadIqH6JBDObBCiF_MNySn4BQqh8aQ8OUYF5muk'\n",
        "MAX_SONGS = 'mix_wo_lonely'\n",
        "\n",
        "#### grap the lyrics #####\n",
        "try:\n",
        "\tdocuments = load('lyrics_array_' + str(MAX_SONGS))\n",
        "\n",
        "except:\n",
        "  artists = []\n",
        "  genius = lyricsgenius.Genius(API_TOKEN, skip_non_songs=True, remove_section_headers=True)\n",
        "  \n",
        "  # lonely = genius.search_artist(\"The Lonely Island\", max_songs=80, sort=\"popularity\")\n",
        "  # artists.append(lonely)\n",
        "\n",
        "  fetty = genius.search_artist(\"Fetty Wap\", max_songs=15, sort=\"popularity\")\n",
        "  artists.append(fetty)\n",
        "  childish = genius.search_artist(\"Childish Gambino\", max_songs=20, sort=\"popularity\")\n",
        "  artists.append(childish)\n",
        "  time.sleep(10)\n",
        "\n",
        "  drake = genius.search_artist(\"Drake\", max_songs=20, sort=\"popularity\")\n",
        "  artists.append(drake)\n",
        "  kendrick = genius.search_artist(\"Kendrick Lamar\", max_songs=20, sort=\"popularity\")\n",
        "  artists.append(kendrick)\n",
        "  time.sleep(20)\n",
        "\n",
        "  drake = genius.search_artist(\"Lil Dicky\", max_songs=20, sort=\"popularity\")\n",
        "  artists.append(drake)\n",
        "  chet = genius.search_artist(\"Chet Faker\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(chet)\n",
        "  time.sleep(30)\n",
        "  \n",
        "  snoop = genius.search_artist(\"Snoop Dogg\", max_songs=15, sort=\"popularity\")\n",
        "  artists.append(snoop)\n",
        "  travis = genius.search_artist(\"Travis Scott\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(travis)\n",
        "  q = genius.search_artist(\"ScHoolboy Q\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(q)\n",
        "  wayne = genius.search_artist(\"Lil Wayne\", max_songs=15, sort=\"popularity\")\n",
        "  artists.append(wayne)\n",
        "  time.sleep(30)\n",
        "\n",
        "  eminem = genius.search_artist(\"Eminem\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(eminem)\n",
        "  ariana = genius.search_artist(\"Ariana Grande\", max_songs=5, sort=\"popularity\")\n",
        "  artists.append(ariana)\n",
        "  wiz = genius.search_artist(\"Wiz Khalifa\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(wiz)\n",
        "  beatles = genius.search_artist(\"The Beatles\", max_songs=15, sort=\"popularity\")\n",
        "  artists.append(beatles)\n",
        "  billie = genius.search_artist(\"Billie Eilish\", max_songs=15, sort=\"popularity\")\n",
        "  artists.append(billie)\n",
        "  peas = genius.search_artist(\"Black Eyed Peas\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(peas)\n",
        "  time.sleep(40)\n",
        "\n",
        "  chance = genius.search_artist(\"Chance The Rapper\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(chance)\n",
        "  kanye = genius.search_artist(\"Kanye West\", max_songs=15, sort=\"popularity\")\n",
        "  artists.append(kanye)\n",
        "  outkast = genius.search_artist(\"OutKast\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(outkast)\n",
        "  rihanna = genius.search_artist(\"Rihanna\", max_songs=10, sort=\"popularity\")\n",
        "  artists.append(rihanna)\n",
        "\n",
        "\n",
        "  documents = []\n",
        "  for artist in artists:\n",
        "    for song in artist.songs: \n",
        "      if artist == artists[0] and song == artist.songs[0]:\n",
        "        continue\n",
        "      documents.append(song.lyrics)\n",
        "\n",
        "save('lyrics_array_' + str(MAX_SONGS), documents)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lyricsgenius in /usr/local/lib/python3.6/dist-packages (1.8.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (4.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Searching for songs by Fetty Wap...\n",
            "\n",
            "Song 1: \"Trap Queen\"\n",
            "Song 2: \"679\"\n",
            "Song 3: \"My Way (Remix)\"\n",
            "Song 4: \"My Way\"\n",
            "Song 5: \"Again\"\n",
            "Song 6: \"Jimmy Choo\"\n",
            "Song 7: \"RGF Island\"\n",
            "Song 8: \"Jugg\"\n",
            "Song 9: \"D.A.M (Dats All Me)\"\n",
            "Song 10: \"Wake Up\"\n",
            "Song 11: \"No Days Off\"\n",
            "Song 12: \"Trap Niggas Freestyle\"\n",
            "Song 13: \"Time\"\n",
            "Song 14: \"ZooWap\"\n",
            "Song 15: \"How We Do Things\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Childish Gambino...\n",
            "\n",
            "Song 1: \"This Is America\"\n",
            "Song 2: \"Redbone\"\n",
            "Song 3: \"V. 3005\"\n",
            "Song 4: \"IV. Sweatpants\"\n",
            "Song 5: \"Bonfire\"\n",
            "Song 6: \"Heartbeat\"\n",
            "Song 7: \"Freaks and Geeks\"\n",
            "Song 8: \"III. Telegraph Ave. (”Oakland” by Lloyd)\"\n",
            "Song 9: \"I. The Worst Guys\"\n",
            "Song 10: \"You See Me\"\n",
            "Song 11: \"Sober\"\n",
            "Song 12: \"Me and Your Mama\"\n",
            "Song 13: \"II. Zealots of Stockholm [Free Information]\"\n",
            "Song 14: \"I. Crawl\"\n",
            "Song 15: \"II. Worldstar\"\n",
            "Song 16: \"Feels Like Summer\"\n",
            "Song 17: \"III. Life: The Biggest Troll [Andrew Auernheimer]\"\n",
            "Song 18: \"That Power\"\n",
            "Song 19: \"L.E.S.\"\n",
            "Song 20: \"II. Shadows\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Drake...\n",
            "\n",
            "Song 1: \"God’s Plan\"\n",
            "Song 2: \"In My Feelings\"\n",
            "Timeout raised and caught:\n",
            "HTTPSConnectionPool(host='api.genius.com', port=443): Read timed out. (read timeout=5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c614ce9feacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lyrics_array_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SONGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7d63b1215b05>\u001b[0m in \u001b[0;36mload\u001b[0;34m(fname, extension)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/lyrics_array_mix_wo_lonely.pickle'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c614ce9feacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mdrake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenius\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Drake\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_songs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"popularity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mkendrick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenius\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kendrick Lamar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_songs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"popularity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lyricsgenius/api.py\u001b[0m in \u001b[0;36msearch_artist\u001b[0;34m(self, artist_name, max_songs, sort, per_page, get_full_info, allow_name_change, artist_id)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'song'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msong_info\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0msong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;31m# Attempt to add the Song to the Artist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lyricsgenius/song.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, json_dict, lyrics)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0msave_lyrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msong\u001b[0m \u001b[0mlyrics\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTXT\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'song'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'song'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjson_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSKOdxSMUle7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "0c860c26-6ed0-4b8e-82fe-59b95ab0222d"
      },
      "source": [
        "save(comedy_rap_prepped,'comedy_rap_prepped.txt')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-10e1dabbd8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomedy_rap_prepped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'comedy_rap_prepped.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-4d87832c6726>\u001b[0m in \u001b[0;36msave\u001b[0;34m(fname, data, extension)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 36] File name too long: 'LD, AKA The Independent Variable\\nTrap God, and we servin\\' out the hallway\\n\\nAyy, where the gold at, baby Fuck I need gold for man\\nAyy, where the clothes at, baby Fuck I need clothes for man\\nAyy, where the dough at, baby\\nIn the bank, you know I ain\\'t tryna blow dat, baby\\nAyy, we gon\\' save that money I\\'m so thrifty\\nAyy, we gon\\' save that money I\\'m so stingy\\nAyy, we gon\\' save that money\\nWhat we doin\\' We gon\\' save dat money\\n\\nThe rap game got it all wrong\\nWe ain\\'t \\'bout to go and spend money just to flex on \\'em\\nWe ain\\'t really got it like y\\'all Yeah, baby!\\nI\\'m a type of motherfucker that\\'ll check the check\\nDo the math, I ain\\'t never gettin\\' robbed No\\nThose margaritas not goin\\' on my card No\\nI ain\\'t \\'bout to split a damn thing for convenience sake\\nI\\'m at the restaurant workin\\' that waitress\\nHold up\\nYou ain\\'t heard of Lil Dave, Yung L the Jew biz major Ayy\\nFuck you know about the world he raised in Fuck\\nI\\'ve been savin\\' money since a motherfucker 13\\nI wear the same pair of jeans every day It\\'s true\\nFree sandwiches, homie, two stamps away It\\'s true\\nBook flight December but I leave in May I do\\nDrugs are generic but still work the same\\nI get logins for Netflix from my cousin Greg\\nThanks, Greg!\\n\\nAyy, where the gold at, baby Yeah baby\\nAyy, where the clothes at, baby Yeah baby\\nAyy, where the dough at, baby\\nIn the bank, you know I ain\\'t tryna blow that, baby\\nAyy, we gon\\' s..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOg0efAUTaNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "comedy_rap_text = ''\n",
        "documents = documents[81:]\n",
        "documents = documents[75:96]\n",
        "for document in documents:\n",
        "  if document is not None:\n",
        "    comedy_rap_text += document + '\\n\\n'\n",
        "\n",
        "comedy_rap_prepped = comedy_rap_text\n",
        "import re\n",
        "pattern = re.compile(r'[(.?)]')\n",
        "comedy_rap_prepped = re.sub(pattern, '', comedy_rap_prepped)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBROFg1RCZPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-klkN5O-qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5110b501-1668-4af9-88e6-e8efca584111"
      },
      "source": [
        "comedy_rap_text = comedy_rap_prepped\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(comedy_rap_text)\n",
        "max_id = len(tokenizer.word_index) \n",
        "dataset_size = tokenizer.document_count\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([comedy_rap_text])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)\n",
        "\n",
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 89) (32, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpAqCOljvoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdI1KOf0kDSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('/content/gdrive/My Drive/rap_bot_v2_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As92lnnXTVKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "4e9feb7e-076d-4b2e-ed79-4639c3cba106"
      },
      "source": [
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
        "                    epochs=10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12624/22297 [===============>..............] - ETA: 56:15 - loss: 1.5479"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4855b00ac645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n\u001b[0;32m----> 2\u001b[0;31m                     epochs=10)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiVw2ecDHv2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)\n",
        "\n",
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
        "\n",
        "\n",
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text\n",
        "\n",
        "tf.random.set_seed(42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7GLFnp8PDJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/gdrive/My Drive/rap_bot_v3_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIfy092Hcn7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = complete_text(\"c\", temperature=0.7, n_chars=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X4GqUEAcEn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6062e01-b5a7-4096-f241-c75221a772c4"
      },
      "source": [
        "f = open('/content/gdrive/My Drive/bot_rap.txt','w+')\n",
        "f.write(text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Y1I6bAltfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "68057cbb-5d34-4753-8f5b-ebf1899bce57"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ck hacey, girl men harders back on the big\n",
            "i only gotta say it come down\n",
            "we're been been riding aramn jam, i'm retire him in like i'm on her get retarded her like the harder like this\n",
            "'cause you was not get so damn day\n",
            "have your out on a boat, ain't now up it's on a boat\n",
            "she don't die with you, no\n",
            "she take oe stave with the creat\n",
            "then the painicaimin' off yeah, my mattertuble\n",
            "let you starting him y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFoNRfOTVynK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}