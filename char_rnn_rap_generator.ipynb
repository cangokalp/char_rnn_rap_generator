{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPieqKnGP0OYWuvZD2fEZzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4m5mNc44dHC",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVi3DWY2OoSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGn2NDY3d74K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Go to my github https://github.com/cangokalp/char_rnn_rap_generator\n",
        "#and download the two files; lyrics_array_mix.pickle - under data folder.\n",
        "#After that run the below cell. \n",
        "#Then on the tab to the left of the screen there is a folder icon, \n",
        "#click that and youll see data folder\n",
        "#click upload and upload the files you downloaded. \n",
        "#Then drag them in the data folder\n",
        "#then you can continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sC-EpAcjSTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# DRIVE_PATH = '/content/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okZ3iyatVLre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_ROOT_DIR = \".\"\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\")\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = os.path.join(PROJECT_ROOT_DIR, \"saved_models\")\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "def save(fname, data, extension=\"pickle\"):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + extension)\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def load(fname, extension='pickle'):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + extension)\n",
        "    \n",
        "    with open(path, 'rb') as f:\n",
        "        item = pickle.load(f)\n",
        "\n",
        "    return item"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47e_XqDIbCuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d9916a0e-6077-4531-86f2-0cb427e7816a"
      },
      "source": [
        "#GRAB TRAINING DATA:\n",
        "documents = load('lyrics_array_mix')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3577ae589ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lyrics_array_mix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-1882e22ba92b>\u001b[0m in \u001b[0;36mload\u001b[0;34m(fname, extension)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/lyrics_array_mix.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxtv1YLAO5LS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d69b582a-04a5-4562-f807-cbeb0070de1d"
      },
      "source": [
        "#CREATE NEW TRAINING DATA - IF YOU WANT\n",
        "\n",
        "import time\n",
        "!pip install lyricsgenius\n",
        "import lyricsgenius\n",
        "\n",
        "API_TOKEN = '1OWmIr37ZuUI5hDXjN_FIXJlbZadIqH6JBDObBCiF_MNySn4BQqh8aQ8OUYF5muk'\n",
        "fname = 'mix'\n",
        "\n",
        "#### grab the lyrics #####\n",
        "artists = []\n",
        "genius = lyricsgenius.Genius(API_TOKEN, skip_non_songs=True, remove_section_headers=True)\n",
        "\n",
        "# lonely = genius.search_artist(\"The Lonely Island\", max_songs=80, sort=\"popularity\")\n",
        "# artists.append(lonely)\n",
        "# time.sleep(30)\n",
        "\n",
        "fetty = genius.search_artist(\"Fetty Wap\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(fetty)\n",
        "childish = genius.search_artist(\"Childish Gambino\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(childish)\n",
        "time.sleep(10)\n",
        "\n",
        "drake = genius.search_artist(\"Drake\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(drake)\n",
        "time.sleep(10)\n",
        "kendrick = genius.search_artist(\"Kendrick Lamar\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(kendrick)\n",
        "time.sleep(20)\n",
        "\n",
        "# dicky = genius.search_artist(\"Lil Dicky\", max_songs=20, sort=\"popularity\")\n",
        "# artists.append(dicky)\n",
        "\n",
        "travis = genius.search_artist(\"Travis Scott\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(travis)\n",
        "q = genius.search_artist(\"ScHoolboy Q\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(q)\n",
        "wayne = genius.search_artist(\"Lil Wayne\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(wayne)\n",
        "time.sleep(30)\n",
        "\n",
        "eminem = genius.search_artist(\"Eminem\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(eminem)\n",
        "ariana = genius.search_artist(\"Ariana Grande\", max_songs=5, sort=\"popularity\")\n",
        "artists.append(ariana)\n",
        "wiz = genius.search_artist(\"Wiz Khalifa\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(wiz)\n",
        "billie = genius.search_artist(\"Billie Eilish\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(billie)\n",
        "peas = genius.search_artist(\"Black Eyed Peas\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(peas)\n",
        "time.sleep(40)\n",
        "\n",
        "chance = genius.search_artist(\"Chance The Rapper\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(chance)\n",
        "kanye = genius.search_artist(\"Kanye West\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(kanye)\n",
        "outkast = genius.search_artist(\"OutKast\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(outkast)\n",
        "rihanna = genius.search_artist(\"Rihanna\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(rihanna)\n",
        "\n",
        "\n",
        "documents = []\n",
        "for artist in artists:\n",
        "  for song in artist.songs: \n",
        "    documents.append(song.lyrics)\n",
        "\n",
        "save('lyrics_array_' + fname, documents)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lyricsgenius in /usr/local/lib/python3.6/dist-packages (1.8.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (4.6.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.9)\n",
            "Searching for songs by Fetty Wap...\n",
            "\n",
            "Song 1: \"Trap Queen\"\n",
            "Song 2: \"679\"\n",
            "Song 3: \"My Way (Remix)\"\n",
            "Song 4: \"My Way\"\n",
            "Song 5: \"Again\"\n",
            "Song 6: \"Jimmy Choo\"\n",
            "Song 7: \"RGF Island\"\n",
            "Song 8: \"Jugg\"\n",
            "Song 9: \"D.A.M (Dats All Me)\"\n",
            "Song 10: \"Wake Up\"\n",
            "Song 11: \"No Days Off\"\n",
            "Song 12: \"Trap Niggas Freestyle\"\n",
            "Song 13: \"Time\"\n",
            "Song 14: \"ZooWap\"\n",
            "Song 15: \"How We Do Things\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Childish Gambino...\n",
            "\n",
            "Song 1: \"This Is America\"\n",
            "Song 2: \"Redbone\"\n",
            "Song 3: \"V. 3005\"\n",
            "Song 4: \"IV. Sweatpants\"\n",
            "Song 5: \"Bonfire\"\n",
            "Song 6: \"Heartbeat\"\n",
            "Song 7: \"Freaks and Geeks\"\n",
            "Song 8: \"III. Telegraph Ave. (”Oakland” by Lloyd)\"\n",
            "Song 9: \"I. The Worst Guys\"\n",
            "Song 10: \"You See Me\"\n",
            "Song 11: \"Sober\"\n",
            "Song 12: \"Me and Your Mama\"\n",
            "Song 13: \"II. Zealots of Stockholm [Free Information]\"\n",
            "Song 14: \"I. Crawl\"\n",
            "Song 15: \"II. Worldstar\"\n",
            "Song 16: \"Feels Like Summer\"\n",
            "Song 17: \"III. Life: The Biggest Troll [Andrew Auernheimer]\"\n",
            "Song 18: \"That Power\"\n",
            "Song 19: \"L.E.S.\"\n",
            "Song 20: \"II. Shadows\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Drake...\n",
            "\n",
            "Song 1: \"God’s Plan\"\n",
            "Song 2: \"In My Feelings\"\n",
            "Song 3: \"Hotline Bling\"\n",
            "Song 4: \"One Dance\"\n",
            "Song 5: \"Hold On, We’re Going Home\"\n",
            "Song 6: \"Know Yourself\"\n",
            "Song 7: \"Back to Back\"\n",
            "Song 8: \"All Me\"\n",
            "Song 9: \"Fake Love\"\n",
            "Song 10: \"From Time\"\n",
            "Song 11: \"0 to 100 / The Catch Up\"\n",
            "Song 12: \"The Motto\"\n",
            "Song 13: \"Started from the Bottom\"\n",
            "Song 14: \"Pound Cake / Paris Morton Music 2\"\n",
            "Song 15: \"HYFR\"\n",
            "Song 16: \"Marvin’s Room\"\n",
            "Song 17: \"Nice For What\"\n",
            "Song 18: \"Passionfruit\"\n",
            "Song 19: \"Child’s Play\"\n",
            "Song 20: \"Energy\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Kendrick Lamar...\n",
            "\n",
            "Song 1: \"HUMBLE.\"\n",
            "Song 2: \"​m.A.A.d city\"\n",
            "Song 3: \"Swimming Pools (Drank)\"\n",
            "Song 4: \"DNA.\"\n",
            "Song 5: \"Money Trees\"\n",
            "Song 6: \"XXX.\"\n",
            "Song 7: \"Bitch, Don’t Kill My Vibe\"\n",
            "Song 8: \"Poetic Justice\"\n",
            "Song 9: \"King Kunta\"\n",
            "Song 10: \"LOVE.\"\n",
            "Song 11: \"Backseat Freestyle\"\n",
            "Song 12: \"Alright\"\n",
            "Song 13: \"The Blacker the Berry\"\n",
            "Song 14: \"ELEMENT.\"\n",
            "Song 15: \"LOYALTY.\"\n",
            "Song 16: \"Sing About Me, I’m Dying of Thirst\"\n",
            "Song 17: \"​i (Album Version)\"\n",
            "Song 18: \"A.D.H.D.\"\n",
            "Song 19: \"FEAR.\"\n",
            "Song 20: \"The Heart Part 4\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Travis Scott...\n",
            "\n",
            "Song 1: \"SICKO MODE\"\n",
            "Song 2: \"​goosebumps\"\n",
            "Song 3: \"BUTTERFLY EFFECT\"\n",
            "Song 4: \"Antidote\"\n",
            "Song 5: \"HIGHEST IN THE ROOM\"\n",
            "Song 6: \"​beibs in the trap\"\n",
            "Song 7: \"STARGAZING\"\n",
            "Song 8: \"YOSEMITE\"\n",
            "Song 9: \"CAN’T SAY\"\n",
            "Song 10: \"90210\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by ScHoolboy Q...\n",
            "\n",
            "Song 1: \"Collard Greens\"\n",
            "Song 2: \"Studio\"\n",
            "Song 3: \"Hands on the Wheel\"\n",
            "Song 4: \"Blessed\"\n",
            "Song 5: \"Man of tHe Year\"\n",
            "Song 6: \"THat Part\"\n",
            "Song 7: \"THat Part (Black Hippy Remix)\"\n",
            "Song 8: \"Break the Bank\"\n",
            "Song 9: \"WHat THey Want\"\n",
            "Song 10: \"Gangsta\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Lil Wayne...\n",
            "\n",
            "Song 1: \"Love Me\"\n",
            "Song 2: \"Believe Me\"\n",
            "Song 3: \"Mona Lisa\"\n",
            "Song 4: \"6 Foot 7 Foot\"\n",
            "Song 5: \"Rich As Fuck\"\n",
            "Song 6: \"Mirror\"\n",
            "Song 7: \"She Will\"\n",
            "Song 8: \"A Milli\"\n",
            "Song 9: \"Don’t Cry\"\n",
            "Song 10: \"Blunt Blowin’\"\n",
            "Song 11: \"No Worries\"\n",
            "Song 12: \"Uproar\"\n",
            "Song 13: \"Right Above It\"\n",
            "Song 14: \"Drop the World\"\n",
            "Song 15: \"John\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Eminem...\n",
            "\n",
            "Song 1: \"Rap God\"\n",
            "Song 2: \"Killshot\"\n",
            "Song 3: \"Lose Yourself\"\n",
            "Song 4: \"The Monster\"\n",
            "Song 5: \"Godzilla\"\n",
            "Song 6: \"Lucky You\"\n",
            "Song 7: \"The Ringer\"\n",
            "Song 8: \"River\"\n",
            "Song 9: \"Venom\"\n",
            "Song 10: \"Berzerk\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Ariana Grande...\n",
            "\n",
            "Song 1: \"​thank u, next\"\n",
            "Song 2: \"7 rings\"\n",
            "Song 3: \"​God is a woman\"\n",
            "Song 4: \"Side To Side\"\n",
            "Song 5: \"​​no tears left to cry\"\n",
            "\n",
            "Reached user-specified song limit (5).\n",
            "Done. Found 5 songs.\n",
            "Searching for songs by Wiz Khalifa...\n",
            "\n",
            "Song 1: \"See You Again\"\n",
            "Song 2: \"Remember You\"\n",
            "Song 3: \"We Dem Boyz\"\n",
            "Song 4: \"Black and Yellow\"\n",
            "Song 5: \"Medicated\"\n",
            "Song 6: \"Work Hard, Play Hard\"\n",
            "Song 7: \"Hopeless Romantic\"\n",
            "Song 8: \"Maan\"\n",
            "Song 9: \"Bake Sale\"\n",
            "Song 10: \"So High (Blacc Hollywood)\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Billie Eilish...\n",
            "\n",
            "Song 1: \"​when the party’s over\"\n",
            "Song 2: \"​bad guy\"\n",
            "Song 3: \"​everything i wanted\"\n",
            "Song 4: \"​idontwannabeyouanymore\"\n",
            "Song 5: \"​bury a friend\"\n",
            "Song 6: \"​i love you\"\n",
            "Song 7: \"​wish you were gay\"\n",
            "Song 8: \"No Time To Die\"\n",
            "Song 9: \"​​ocean eyes\"\n",
            "Song 10: \"​you should see me in a crown\"\n",
            "Song 11: \"​bellyache\"\n",
            "Song 12: \"​all the good girls go to hell\"\n",
            "Song 13: \"COPYCAT\"\n",
            "Song 14: \"​xanny\"\n",
            "Song 15: \"​my strange addiction\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Black Eyed Peas...\n",
            "\n",
            "Changing artist name to 'The Black Eyed Peas'\n",
            "Song 1: \"Where Is the Love?\"\n",
            "Song 2: \"My Humps\"\n",
            "Song 3: \"#WHERESTHELOVE\"\n",
            "Song 4: \"I Gotta Feeling\"\n",
            "Song 5: \"Meet Me Halfway\"\n",
            "Song 6: \"Boom Boom Pow\"\n",
            "Song 7: \"Pump It\"\n",
            "Song 8: \"Just Can’t Get Enough\"\n",
            "Song 9: \"Let’s Get it Started\"\n",
            "Song 10: \"Let’s Get Retarded\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Chance The Rapper...\n",
            "\n",
            "Changing artist name to 'Chance the Rapper'\n",
            "Song 1: \"Cocoa Butter Kisses\"\n",
            "Song 2: \"No Problem\"\n",
            "Song 3: \"Favorite Song\"\n",
            "Song 4: \"Juice\"\n",
            "Song 5: \"Pusha Man/Paranoia\"\n",
            "Song 6: \"Same Drugs\"\n",
            "Song 7: \"Blessings\"\n",
            "Song 8: \"Lost\"\n",
            "Song 9: \"Acid Rain\"\n",
            "Song 10: \"Angels\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Kanye West...\n",
            "\n",
            "Song 1: \"Mercy\"\n",
            "Song 2: \"Father Stretch My Hands, Pt. 1\"\n",
            "Song 3: \"Monster\"\n",
            "Song 4: \"Ultralight Beam\"\n",
            "Song 5: \"Bound 2\"\n",
            "Song 6: \"New Slaves\"\n",
            "Song 7: \"Blood on the Leaves\"\n",
            "Song 8: \"Black Skinhead\"\n",
            "Song 9: \"All Mine\"\n",
            "Song 10: \"Famous\"\n",
            "Song 11: \"Real Friends\"\n",
            "Song 12: \"Runaway\"\n",
            "Song 13: \"I Love Kanye\"\n",
            "Song 14: \"POWER\"\n",
            "Song 15: \"Wolves\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by OutKast...\n",
            "\n",
            "Song 1: \"Hey Ya!\"\n",
            "Song 2: \"Ms. Jackson\"\n",
            "Song 3: \"Roses\"\n",
            "Song 4: \"Aquemini\"\n",
            "Song 5: \"ATLiens\"\n",
            "Song 6: \"B.O.B\"\n",
            "Song 7: \"So Fresh, So Clean\"\n",
            "Song 8: \"SpottieOttieDopaliscious\"\n",
            "Song 9: \"Rosa Parks\"\n",
            "Song 10: \"Da Art of Storytellin’ (Pt. 1)\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Rihanna...\n",
            "\n",
            "Song 1: \"Work\"\n",
            "Song 2: \"Needed Me\"\n",
            "Song 3: \"Love on the Brain\"\n",
            "Song 4: \"Stay\"\n",
            "Song 5: \"Kiss it Better\"\n",
            "Song 6: \"Sex with Me\"\n",
            "Song 7: \"Bitch Better Have My Money\"\n",
            "Song 8: \"Consideration\"\n",
            "Song 9: \"Diamonds\"\n",
            "Song 10: \"Desperado\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_8esvPZ0FkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path='/content/gdrive/My Drive/lyrics_array_mix.pickle'\n",
        "# with open(path, 'wb') as f:\n",
        "#     pickle.dump(documents, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzBbUU-zdUuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COMBINE ALL SONGS INTO ONE TEXT FILE\n",
        "\n",
        "comedy_rap_text = ''\n",
        "for document in documents:\n",
        "  if document is not None:\n",
        "    comedy_rap_text += document + '\\n'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbFGKmYdt1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLEAN THE TEXT, GET RID OF SOME PATTERNS\n",
        "\n",
        "comedy_rap_prepped = comedy_rap_text\n",
        "import re\n",
        "pattern = re.compile(r'[(.?)]')\n",
        "comedy_rap_prepped = re.sub(pattern, '', comedy_rap_prepped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBROFg1RCZPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpu_info = !nvidia-smi\n",
        "# gpu_info = '\\n'.join(gpu_info)\n",
        "# if gpu_info.find('failed') >= 0:\n",
        "#   print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "#   print('and then re-execute this cell.')\n",
        "# else:\n",
        "#   print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIlUY5SsymBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rap_bot_v3 will use statefull RNN. Basically in a stateful model \n",
        "# after each training batch the final state is kept and used as initial state for next batch\n",
        "statefull = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-klkN5O-qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREPROCESSING THE TRAINING DATA SO THAT CHAR MODEL CAN USE\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(comedy_rap_prepped)\n",
        "max_id = len(tokenizer.word_index) \n",
        "dataset_size = tokenizer.document_count\n",
        "\n",
        "train_size = dataset_size * 90 // 100\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([comedy_rap_prepped])) - 1\n",
        "\n",
        "if not statefull:\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "  dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  batch_size = 32\n",
        "  dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "  dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "  dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "  dataset = dataset.prefetch(1)\n",
        "\n",
        "  for X_batch, Y_batch in dataset.take(1):\n",
        "      print(X_batch.shape, Y_batch.shape)\n",
        "else:\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "  dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "  dataset = dataset.repeat().batch(1)\n",
        "  dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "  dataset = dataset.map(\n",
        "      lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "  dataset = dataset.prefetch(1)\n",
        "\n",
        "  batch_size = 32\n",
        "  encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "  datasets = []\n",
        "  for encoded_part in encoded_parts:\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "      dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "      dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "      datasets.append(dataset)\n",
        "  dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "  dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "  dataset = dataset.map(\n",
        "      lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "  dataset = dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9-upMafXBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.load_model(os.path.join(DRIVE_PATH, 'rap_bot_v2_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpAqCOljvoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IF YOU WANT TO TRAIN FROM SCRATCH - RNN NETWORK WITH DROPOUT\n",
        "if not statefull:\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                      dropout=0.2, recurrent_dropout=0.2),\n",
        "      keras.layers.GRU(128, return_sequences=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.2),\n",
        "      keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                      activation=\"softmax\"))\n",
        "  ])\n",
        "\n",
        "else:\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.GRU(256, return_sequences=True, stateful=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.3,\n",
        "                      batch_input_shape=[batch_size, None, max_id]),\n",
        "      keras.layers.GRU(256, return_sequences=True, stateful=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.GRU(256, return_sequences=True, stateful=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                      activation=\"softmax\"))\n",
        "  ])\n",
        "\n",
        "  class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()\n",
        "\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As92lnnXTVKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not statefull:\n",
        "  history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=10)\n",
        "else:\n",
        "  steps_per_epoch = train_size // batch_size // n_steps\n",
        "  history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=40,\n",
        "                    callbacks=[ResetStatesCallback()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcDCUx5jzfUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if statefull:\n",
        "  stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "  ])\n",
        "  stateless_model.build(tf.TensorShape([None, None, max_id]))\n",
        "  stateless_model.set_weights(model.get_weights())\n",
        "  model = stateless_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-7Fzn4f0cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO SAVE THE TRAINED NEW MODEL\n",
        "model.save('./saved_models/rap_bot_v3_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiVw2ecDHv2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HELPER FUNCTIONS FOR NEW LYRICS GENERATION\n",
        "\n",
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)\n",
        "\n",
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
        "\n",
        "\n",
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIfy092Hcn7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIS WILL GENERATE WARNINGS - JUST IGNORE\n",
        "# temperature param represents how the next word is sampled, close to 0 just does argmax, \n",
        "# around 1 worked good for me you can just try different and look at the results\n",
        "# to not to keep generating same things usually they dont do argmax over the probabilities instead you sample from them with the prob of the probabilities\n",
        "# n_chars - number of characters you want to generate\n",
        "tf.random.set_seed(42)\n",
        "text = complete_text(\"y\", temperature=1, n_chars=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Y1I6bAltfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !!!!! LETS SEEE :D\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1hY2qxiIs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}