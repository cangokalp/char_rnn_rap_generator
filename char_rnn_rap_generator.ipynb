{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMvmhAwujlwNzNJ7PMao+YI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4m5mNc44dHC",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVi3DWY2OoSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGn2NDY3d74K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Go to my github https://github.com/cangokalp/char_rnn_rap_generator\n",
        "#and download the two files; lyrics_array_mix.pickle - under data folder.\n",
        "#After that run the below cell. \n",
        "#Then on the tab to the left of the screen there is a folder icon, \n",
        "#click that and youll see data folder\n",
        "#click upload and upload the files you downloaded. \n",
        "#Then drag them in the data folder\n",
        "#then you can continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sC-EpAcjSTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# DRIVE_PATH = '/content/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okZ3iyatVLre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_ROOT_DIR = \".\"\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\")\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = os.path.join(PROJECT_ROOT_DIR, \"saved_models\")\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "def save(fname, data, extension=\"pickle\"):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + extension)\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def load(fname, extension='pickle'):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + extension)\n",
        "    \n",
        "    with open(path, 'rb') as f:\n",
        "        item = pickle.load(f)\n",
        "\n",
        "    return item"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47e_XqDIbCuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRAB TRAINING DATA:\n",
        "documents = load('lyrics_array_mix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxtv1YLAO5LS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d69b582a-04a5-4562-f807-cbeb0070de1d"
      },
      "source": [
        "#CREATE NEW TRAINING DATA - IF YOU WANT\n",
        "\n",
        "import time\n",
        "!pip install lyricsgenius\n",
        "import lyricsgenius\n",
        "\n",
        "API_TOKEN = '1OWmIr37ZuUI5hDXjN_FIXJlbZadIqH6JBDObBCiF_MNySn4BQqh8aQ8OUYF5muk'\n",
        "fname = 'mix'\n",
        "\n",
        "#### grab the lyrics #####\n",
        "artists = []\n",
        "genius = lyricsgenius.Genius(API_TOKEN, skip_non_songs=True, remove_section_headers=True)\n",
        "\n",
        "# lonely = genius.search_artist(\"The Lonely Island\", max_songs=80, sort=\"popularity\")\n",
        "# artists.append(lonely)\n",
        "# time.sleep(30)\n",
        "\n",
        "fetty = genius.search_artist(\"Fetty Wap\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(fetty)\n",
        "childish = genius.search_artist(\"Childish Gambino\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(childish)\n",
        "time.sleep(10)\n",
        "\n",
        "drake = genius.search_artist(\"Drake\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(drake)\n",
        "time.sleep(10)\n",
        "kendrick = genius.search_artist(\"Kendrick Lamar\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(kendrick)\n",
        "time.sleep(20)\n",
        "\n",
        "# dicky = genius.search_artist(\"Lil Dicky\", max_songs=20, sort=\"popularity\")\n",
        "# artists.append(dicky)\n",
        "\n",
        "travis = genius.search_artist(\"Travis Scott\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(travis)\n",
        "q = genius.search_artist(\"ScHoolboy Q\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(q)\n",
        "wayne = genius.search_artist(\"Lil Wayne\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(wayne)\n",
        "time.sleep(30)\n",
        "\n",
        "eminem = genius.search_artist(\"Eminem\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(eminem)\n",
        "ariana = genius.search_artist(\"Ariana Grande\", max_songs=5, sort=\"popularity\")\n",
        "artists.append(ariana)\n",
        "wiz = genius.search_artist(\"Wiz Khalifa\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(wiz)\n",
        "billie = genius.search_artist(\"Billie Eilish\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(billie)\n",
        "peas = genius.search_artist(\"Black Eyed Peas\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(peas)\n",
        "time.sleep(40)\n",
        "\n",
        "chance = genius.search_artist(\"Chance The Rapper\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(chance)\n",
        "kanye = genius.search_artist(\"Kanye West\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(kanye)\n",
        "outkast = genius.search_artist(\"OutKast\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(outkast)\n",
        "rihanna = genius.search_artist(\"Rihanna\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(rihanna)\n",
        "\n",
        "\n",
        "documents = []\n",
        "for artist in artists:\n",
        "  for song in artist.songs: \n",
        "    documents.append(song.lyrics)\n",
        "\n",
        "save('lyrics_array_' + fname, documents)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lyricsgenius in /usr/local/lib/python3.6/dist-packages (1.8.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (4.6.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.9)\n",
            "Searching for songs by Fetty Wap...\n",
            "\n",
            "Song 1: \"Trap Queen\"\n",
            "Song 2: \"679\"\n",
            "Song 3: \"My Way (Remix)\"\n",
            "Song 4: \"My Way\"\n",
            "Song 5: \"Again\"\n",
            "Song 6: \"Jimmy Choo\"\n",
            "Song 7: \"RGF Island\"\n",
            "Song 8: \"Jugg\"\n",
            "Song 9: \"D.A.M (Dats All Me)\"\n",
            "Song 10: \"Wake Up\"\n",
            "Song 11: \"No Days Off\"\n",
            "Song 12: \"Trap Niggas Freestyle\"\n",
            "Song 13: \"Time\"\n",
            "Song 14: \"ZooWap\"\n",
            "Song 15: \"How We Do Things\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Childish Gambino...\n",
            "\n",
            "Song 1: \"This Is America\"\n",
            "Song 2: \"Redbone\"\n",
            "Song 3: \"V. 3005\"\n",
            "Song 4: \"IV. Sweatpants\"\n",
            "Song 5: \"Bonfire\"\n",
            "Song 6: \"Heartbeat\"\n",
            "Song 7: \"Freaks and Geeks\"\n",
            "Song 8: \"III. Telegraph Ave. (”Oakland” by Lloyd)\"\n",
            "Song 9: \"I. The Worst Guys\"\n",
            "Song 10: \"You See Me\"\n",
            "Song 11: \"Sober\"\n",
            "Song 12: \"Me and Your Mama\"\n",
            "Song 13: \"II. Zealots of Stockholm [Free Information]\"\n",
            "Song 14: \"I. Crawl\"\n",
            "Song 15: \"II. Worldstar\"\n",
            "Song 16: \"Feels Like Summer\"\n",
            "Song 17: \"III. Life: The Biggest Troll [Andrew Auernheimer]\"\n",
            "Song 18: \"That Power\"\n",
            "Song 19: \"L.E.S.\"\n",
            "Song 20: \"II. Shadows\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Drake...\n",
            "\n",
            "Song 1: \"God’s Plan\"\n",
            "Song 2: \"In My Feelings\"\n",
            "Song 3: \"Hotline Bling\"\n",
            "Song 4: \"One Dance\"\n",
            "Song 5: \"Hold On, We’re Going Home\"\n",
            "Song 6: \"Know Yourself\"\n",
            "Song 7: \"Back to Back\"\n",
            "Song 8: \"All Me\"\n",
            "Song 9: \"Fake Love\"\n",
            "Song 10: \"From Time\"\n",
            "Song 11: \"0 to 100 / The Catch Up\"\n",
            "Song 12: \"The Motto\"\n",
            "Song 13: \"Started from the Bottom\"\n",
            "Song 14: \"Pound Cake / Paris Morton Music 2\"\n",
            "Song 15: \"HYFR\"\n",
            "Song 16: \"Marvin’s Room\"\n",
            "Song 17: \"Nice For What\"\n",
            "Song 18: \"Passionfruit\"\n",
            "Song 19: \"Child’s Play\"\n",
            "Song 20: \"Energy\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Kendrick Lamar...\n",
            "\n",
            "Song 1: \"HUMBLE.\"\n",
            "Song 2: \"​m.A.A.d city\"\n",
            "Song 3: \"Swimming Pools (Drank)\"\n",
            "Song 4: \"DNA.\"\n",
            "Song 5: \"Money Trees\"\n",
            "Song 6: \"XXX.\"\n",
            "Song 7: \"Bitch, Don’t Kill My Vibe\"\n",
            "Song 8: \"Poetic Justice\"\n",
            "Song 9: \"King Kunta\"\n",
            "Song 10: \"LOVE.\"\n",
            "Song 11: \"Backseat Freestyle\"\n",
            "Song 12: \"Alright\"\n",
            "Song 13: \"The Blacker the Berry\"\n",
            "Song 14: \"ELEMENT.\"\n",
            "Song 15: \"LOYALTY.\"\n",
            "Song 16: \"Sing About Me, I’m Dying of Thirst\"\n",
            "Song 17: \"​i (Album Version)\"\n",
            "Song 18: \"A.D.H.D.\"\n",
            "Song 19: \"FEAR.\"\n",
            "Song 20: \"The Heart Part 4\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n",
            "Searching for songs by Travis Scott...\n",
            "\n",
            "Song 1: \"SICKO MODE\"\n",
            "Song 2: \"​goosebumps\"\n",
            "Song 3: \"BUTTERFLY EFFECT\"\n",
            "Song 4: \"Antidote\"\n",
            "Song 5: \"HIGHEST IN THE ROOM\"\n",
            "Song 6: \"​beibs in the trap\"\n",
            "Song 7: \"STARGAZING\"\n",
            "Song 8: \"YOSEMITE\"\n",
            "Song 9: \"CAN’T SAY\"\n",
            "Song 10: \"90210\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by ScHoolboy Q...\n",
            "\n",
            "Song 1: \"Collard Greens\"\n",
            "Song 2: \"Studio\"\n",
            "Song 3: \"Hands on the Wheel\"\n",
            "Song 4: \"Blessed\"\n",
            "Song 5: \"Man of tHe Year\"\n",
            "Song 6: \"THat Part\"\n",
            "Song 7: \"THat Part (Black Hippy Remix)\"\n",
            "Song 8: \"Break the Bank\"\n",
            "Song 9: \"WHat THey Want\"\n",
            "Song 10: \"Gangsta\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Lil Wayne...\n",
            "\n",
            "Song 1: \"Love Me\"\n",
            "Song 2: \"Believe Me\"\n",
            "Song 3: \"Mona Lisa\"\n",
            "Song 4: \"6 Foot 7 Foot\"\n",
            "Song 5: \"Rich As Fuck\"\n",
            "Song 6: \"Mirror\"\n",
            "Song 7: \"She Will\"\n",
            "Song 8: \"A Milli\"\n",
            "Song 9: \"Don’t Cry\"\n",
            "Song 10: \"Blunt Blowin’\"\n",
            "Song 11: \"No Worries\"\n",
            "Song 12: \"Uproar\"\n",
            "Song 13: \"Right Above It\"\n",
            "Song 14: \"Drop the World\"\n",
            "Song 15: \"John\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Eminem...\n",
            "\n",
            "Song 1: \"Rap God\"\n",
            "Song 2: \"Killshot\"\n",
            "Song 3: \"Lose Yourself\"\n",
            "Song 4: \"The Monster\"\n",
            "Song 5: \"Godzilla\"\n",
            "Song 6: \"Lucky You\"\n",
            "Song 7: \"The Ringer\"\n",
            "Song 8: \"River\"\n",
            "Song 9: \"Venom\"\n",
            "Song 10: \"Berzerk\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Ariana Grande...\n",
            "\n",
            "Song 1: \"​thank u, next\"\n",
            "Song 2: \"7 rings\"\n",
            "Song 3: \"​God is a woman\"\n",
            "Song 4: \"Side To Side\"\n",
            "Song 5: \"​​no tears left to cry\"\n",
            "\n",
            "Reached user-specified song limit (5).\n",
            "Done. Found 5 songs.\n",
            "Searching for songs by Wiz Khalifa...\n",
            "\n",
            "Song 1: \"See You Again\"\n",
            "Song 2: \"Remember You\"\n",
            "Song 3: \"We Dem Boyz\"\n",
            "Song 4: \"Black and Yellow\"\n",
            "Song 5: \"Medicated\"\n",
            "Song 6: \"Work Hard, Play Hard\"\n",
            "Song 7: \"Hopeless Romantic\"\n",
            "Song 8: \"Maan\"\n",
            "Song 9: \"Bake Sale\"\n",
            "Song 10: \"So High (Blacc Hollywood)\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Billie Eilish...\n",
            "\n",
            "Song 1: \"​when the party’s over\"\n",
            "Song 2: \"​bad guy\"\n",
            "Song 3: \"​everything i wanted\"\n",
            "Song 4: \"​idontwannabeyouanymore\"\n",
            "Song 5: \"​bury a friend\"\n",
            "Song 6: \"​i love you\"\n",
            "Song 7: \"​wish you were gay\"\n",
            "Song 8: \"No Time To Die\"\n",
            "Song 9: \"​​ocean eyes\"\n",
            "Song 10: \"​you should see me in a crown\"\n",
            "Song 11: \"​bellyache\"\n",
            "Song 12: \"​all the good girls go to hell\"\n",
            "Song 13: \"COPYCAT\"\n",
            "Song 14: \"​xanny\"\n",
            "Song 15: \"​my strange addiction\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by Black Eyed Peas...\n",
            "\n",
            "Changing artist name to 'The Black Eyed Peas'\n",
            "Song 1: \"Where Is the Love?\"\n",
            "Song 2: \"My Humps\"\n",
            "Song 3: \"#WHERESTHELOVE\"\n",
            "Song 4: \"I Gotta Feeling\"\n",
            "Song 5: \"Meet Me Halfway\"\n",
            "Song 6: \"Boom Boom Pow\"\n",
            "Song 7: \"Pump It\"\n",
            "Song 8: \"Just Can’t Get Enough\"\n",
            "Song 9: \"Let’s Get it Started\"\n",
            "Song 10: \"Let’s Get Retarded\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Chance The Rapper...\n",
            "\n",
            "Changing artist name to 'Chance the Rapper'\n",
            "Song 1: \"Cocoa Butter Kisses\"\n",
            "Song 2: \"No Problem\"\n",
            "Song 3: \"Favorite Song\"\n",
            "Song 4: \"Juice\"\n",
            "Song 5: \"Pusha Man/Paranoia\"\n",
            "Song 6: \"Same Drugs\"\n",
            "Song 7: \"Blessings\"\n",
            "Song 8: \"Lost\"\n",
            "Song 9: \"Acid Rain\"\n",
            "Song 10: \"Angels\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Kanye West...\n",
            "\n",
            "Song 1: \"Mercy\"\n",
            "Song 2: \"Father Stretch My Hands, Pt. 1\"\n",
            "Song 3: \"Monster\"\n",
            "Song 4: \"Ultralight Beam\"\n",
            "Song 5: \"Bound 2\"\n",
            "Song 6: \"New Slaves\"\n",
            "Song 7: \"Blood on the Leaves\"\n",
            "Song 8: \"Black Skinhead\"\n",
            "Song 9: \"All Mine\"\n",
            "Song 10: \"Famous\"\n",
            "Song 11: \"Real Friends\"\n",
            "Song 12: \"Runaway\"\n",
            "Song 13: \"I Love Kanye\"\n",
            "Song 14: \"POWER\"\n",
            "Song 15: \"Wolves\"\n",
            "\n",
            "Reached user-specified song limit (15).\n",
            "Done. Found 15 songs.\n",
            "Searching for songs by OutKast...\n",
            "\n",
            "Song 1: \"Hey Ya!\"\n",
            "Song 2: \"Ms. Jackson\"\n",
            "Song 3: \"Roses\"\n",
            "Song 4: \"Aquemini\"\n",
            "Song 5: \"ATLiens\"\n",
            "Song 6: \"B.O.B\"\n",
            "Song 7: \"So Fresh, So Clean\"\n",
            "Song 8: \"SpottieOttieDopaliscious\"\n",
            "Song 9: \"Rosa Parks\"\n",
            "Song 10: \"Da Art of Storytellin’ (Pt. 1)\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n",
            "Searching for songs by Rihanna...\n",
            "\n",
            "Song 1: \"Work\"\n",
            "Song 2: \"Needed Me\"\n",
            "Song 3: \"Love on the Brain\"\n",
            "Song 4: \"Stay\"\n",
            "Song 5: \"Kiss it Better\"\n",
            "Song 6: \"Sex with Me\"\n",
            "Song 7: \"Bitch Better Have My Money\"\n",
            "Song 8: \"Consideration\"\n",
            "Song 9: \"Diamonds\"\n",
            "Song 10: \"Desperado\"\n",
            "\n",
            "Reached user-specified song limit (10).\n",
            "Done. Found 10 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_8esvPZ0FkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path='/content/gdrive/My Drive/lyrics_array_mix.pickle'\n",
        "# with open(path, 'wb') as f:\n",
        "#     pickle.dump(documents, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzBbUU-zdUuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COMBINE ALL SONGS INTO ONE TEXT FILE\n",
        "\n",
        "comedy_rap_text = ''\n",
        "for document in documents:\n",
        "  if document is not None:\n",
        "    comedy_rap_text += document + '\\n'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbFGKmYdt1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLEAN THE TEXT, GET RID OF SOME PATTERNS\n",
        "\n",
        "comedy_rap_prepped = comedy_rap_text\n",
        "import re\n",
        "pattern = re.compile(r'[(.?)]')\n",
        "comedy_rap_prepped = re.sub(pattern, '', comedy_rap_prepped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBROFg1RCZPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a94cedd9-3e12-4692-c9a2-d89865b3e371"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May  6 21:44:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIlUY5SsymBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rap_bot_v3 will use statefull RNN - expecting it to do better than rap_bot_v2 which used stateless RNN\n",
        "# Basically in a stateful model \n",
        "# after each training batch the final state is kept and used as initial state for next batch\n",
        "# this way it'll remember things beyond 100 chars\n",
        "statefull = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-klkN5O-qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREPROCESSING THE TRAINING DATA SO THAT CHAR MODEL CAN USE\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(comedy_rap_prepped)\n",
        "max_id = len(tokenizer.word_index) \n",
        "dataset_size = tokenizer.document_count\n",
        "\n",
        "train_size = dataset_size * 90 // 100\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([comedy_rap_prepped])) - 1\n",
        "\n",
        "if not statefull:\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "  dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  batch_size = 32\n",
        "  dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "  dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "  dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "  dataset = dataset.prefetch(1)\n",
        "\n",
        "  for X_batch, Y_batch in dataset.take(1):\n",
        "      print(X_batch.shape, Y_batch.shape)\n",
        "else:\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "  dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "  dataset = dataset.repeat().batch(1)\n",
        "  dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "  dataset = dataset.map(\n",
        "      lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "  dataset = dataset.prefetch(1)\n",
        "\n",
        "  batch_size = 32\n",
        "  encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "  datasets = []\n",
        "  for encoded_part in encoded_parts:\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "      dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "      dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "      datasets.append(dataset)\n",
        "  dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "  dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "  dataset = dataset.map(\n",
        "      lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "  dataset = dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9-upMafXBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.load_model(os.path.join(DRIVE_PATH, 'rap_bot_v3_model.h5')\n",
        "# model = keras.models.load_model(os.path.join('./saved_models', 'rap_bot_v3_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpAqCOljvoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2c036079-a3e2-4d14-d942-7054a02eb619"
      },
      "source": [
        "# IF YOU WANT TO TRAIN FROM SCRATCH - RNN NETWORK WITH DROPOUT\n",
        "if not statefull:\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                      dropout=0.2, recurrent_dropout=0.2),\n",
        "      keras.layers.GRU(128, return_sequences=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.2),\n",
        "      keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                      activation=\"softmax\"))\n",
        "  ])\n",
        "\n",
        "else:\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.GRU(256, return_sequences=True, stateful=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.3,\n",
        "                      batch_input_shape=[batch_size, None, max_id]),\n",
        "      keras.layers.GRU(256, return_sequences=True, stateful=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.GRU(256, return_sequences=True, stateful=True,\n",
        "                      dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                      activation=\"softmax\"))\n",
        "  ])\n",
        "\n",
        "  class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()\n",
        "\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As92lnnXTVKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6670bc89-7d06-490f-b137-7d94e18c4f7a"
      },
      "source": [
        "if not statefull:\n",
        "  history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=10)\n",
        "else:\n",
        "  steps_per_epoch = train_size // batch_size // n_steps\n",
        "  history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=50,\n",
        "                    callbacks=[ResetStatesCallback()])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "173/173 [==============================] - 61s 354ms/step - loss: 2.6654\n",
            "Epoch 2/50\n",
            "173/173 [==============================] - 61s 352ms/step - loss: 2.2053\n",
            "Epoch 3/50\n",
            "173/173 [==============================] - 60s 348ms/step - loss: 2.0797\n",
            "Epoch 4/50\n",
            "173/173 [==============================] - 60s 349ms/step - loss: 2.0132\n",
            "Epoch 5/50\n",
            "173/173 [==============================] - 60s 346ms/step - loss: 2.4577\n",
            "Epoch 6/50\n",
            "173/173 [==============================] - 60s 345ms/step - loss: 2.4000\n",
            "Epoch 7/50\n",
            "173/173 [==============================] - 59s 343ms/step - loss: 2.5996\n",
            "Epoch 8/50\n",
            "173/173 [==============================] - 59s 342ms/step - loss: 2.3306\n",
            "Epoch 9/50\n",
            "173/173 [==============================] - 60s 345ms/step - loss: 2.3576\n",
            "Epoch 10/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 2.2562\n",
            "Epoch 11/50\n",
            "173/173 [==============================] - 59s 341ms/step - loss: 2.2079\n",
            "Epoch 12/50\n",
            "173/173 [==============================] - 59s 339ms/step - loss: 1.9307\n",
            "Epoch 13/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 2.0793\n",
            "Epoch 14/50\n",
            "173/173 [==============================] - 59s 341ms/step - loss: 2.0723\n",
            "Epoch 15/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 1.6293\n",
            "Epoch 16/50\n",
            "173/173 [==============================] - 59s 341ms/step - loss: 1.5914\n",
            "Epoch 17/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 1.5698\n",
            "Epoch 18/50\n",
            "173/173 [==============================] - 59s 339ms/step - loss: 1.5513\n",
            "Epoch 19/50\n",
            "173/173 [==============================] - 59s 339ms/step - loss: 1.5365\n",
            "Epoch 20/50\n",
            "173/173 [==============================] - 58s 338ms/step - loss: 1.5255\n",
            "Epoch 21/50\n",
            "173/173 [==============================] - 58s 337ms/step - loss: 1.5133\n",
            "Epoch 22/50\n",
            "173/173 [==============================] - 58s 336ms/step - loss: 1.5011\n",
            "Epoch 23/50\n",
            "173/173 [==============================] - 58s 336ms/step - loss: 1.4911\n",
            "Epoch 24/50\n",
            "173/173 [==============================] - 58s 334ms/step - loss: 1.4827\n",
            "Epoch 25/50\n",
            "173/173 [==============================] - 59s 338ms/step - loss: 1.4759\n",
            "Epoch 26/50\n",
            "173/173 [==============================] - 58s 334ms/step - loss: 1.4679\n",
            "Epoch 27/50\n",
            "173/173 [==============================] - 58s 335ms/step - loss: 1.4613\n",
            "Epoch 28/50\n",
            "173/173 [==============================] - 58s 336ms/step - loss: 1.4552\n",
            "Epoch 29/50\n",
            "173/173 [==============================] - 58s 336ms/step - loss: 1.4469\n",
            "Epoch 30/50\n",
            "173/173 [==============================] - 58s 338ms/step - loss: 1.4437\n",
            "Epoch 31/50\n",
            "173/173 [==============================] - 59s 339ms/step - loss: 1.4377\n",
            "Epoch 32/50\n",
            "173/173 [==============================] - 58s 337ms/step - loss: 1.4328\n",
            "Epoch 33/50\n",
            "173/173 [==============================] - 58s 335ms/step - loss: 1.4271\n",
            "Epoch 34/50\n",
            "173/173 [==============================] - 59s 339ms/step - loss: 1.4247\n",
            "Epoch 35/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 1.4190\n",
            "Epoch 36/50\n",
            "173/173 [==============================] - 59s 341ms/step - loss: 1.4140\n",
            "Epoch 37/50\n",
            "173/173 [==============================] - 59s 343ms/step - loss: 1.4108\n",
            "Epoch 38/50\n",
            "173/173 [==============================] - 59s 342ms/step - loss: 1.4067\n",
            "Epoch 39/50\n",
            "173/173 [==============================] - 59s 343ms/step - loss: 1.4028\n",
            "Epoch 40/50\n",
            "173/173 [==============================] - 59s 343ms/step - loss: 1.4381\n",
            "Epoch 41/50\n",
            "173/173 [==============================] - 59s 344ms/step - loss: 1.3974\n",
            "Epoch 42/50\n",
            "173/173 [==============================] - 60s 346ms/step - loss: 1.3945\n",
            "Epoch 43/50\n",
            "173/173 [==============================] - 59s 344ms/step - loss: 1.4300\n",
            "Epoch 44/50\n",
            "173/173 [==============================] - 59s 343ms/step - loss: 1.3887\n",
            "Epoch 45/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 1.3867\n",
            "Epoch 46/50\n",
            "173/173 [==============================] - 59s 341ms/step - loss: 1.3825\n",
            "Epoch 47/50\n",
            "173/173 [==============================] - 59s 341ms/step - loss: 1.3795\n",
            "Epoch 48/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 1.3785\n",
            "Epoch 49/50\n",
            "173/173 [==============================] - 59s 340ms/step - loss: 1.3752\n",
            "Epoch 50/50\n",
            "173/173 [==============================] - 58s 337ms/step - loss: 1.3735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcDCUx5jzfUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if statefull:\n",
        "  stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(256, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(256, return_sequences=True),\n",
        "    keras.layers.GRU(256, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "  ])\n",
        "  stateless_model.build(tf.TensorShape([None, None, max_id]))\n",
        "  stateless_model.set_weights(model.get_weights())\n",
        "  model = stateless_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-7Fzn4f0cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "98a7b380-b014-4d63-8a69-9131af3453b1"
      },
      "source": [
        "# SAVE THE TRAINED NEW MODEL\n",
        "model.save('./saved_models/rap_bot_v3_model.h5')\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# DRIVE_PATH = '/content/gdrive/My Drive'\n",
        "# model.save(DRIVE_PATH + '/rap_bot_v3_model.h5')\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiVw2ecDHv2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HELPER FUNCTIONS FOR NEW LYRICS GENERATION\n",
        "\n",
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)\n",
        "\n",
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
        "\n",
        "\n",
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIfy092Hcn7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "f1508882-9013-4f03-8892-9b3f29b30397"
      },
      "source": [
        "# THIS WILL GENERATE WARNINGS - JUST IGNORE\n",
        "# temperature param represents how the next word is sampled, close to 0 just does argmax, \n",
        "# around 1 worked good for me you can just try different and look at the results\n",
        "# to not to keep generating same things usually they dont do argmax over the probabilities instead you sample from them with the prob of the probabilities\n",
        "# n_chars - number of characters you want to generate\n",
        "tf.random.set_seed(42)\n",
        "text = complete_text(\"h\", temperature=1, n_chars=400)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7ce942df7278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-1815e437dcd2>\u001b[0m in \u001b[0;36mcomplete_text\u001b[0;34m(text, n_chars, temperature)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomplete_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnext_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-1815e437dcd2>\u001b[0m in \u001b[0;36mnext_char\u001b[0;34m(text, temperature)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnext_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mrescaled_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mchar_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescaled_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Y1I6bAltfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !!!!! LETS SEEE :D\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1hY2qxiIs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}