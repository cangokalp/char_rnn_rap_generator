{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNFiJW5s3KrQHi2JEOFFDzC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4m5mNc44dHC",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/cangokalp/char_rnn_rap_generator/blob/master/char_rnn_rap_generator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVi3DWY2OoSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGn2NDY3d74K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Go to my github https://github.com/cangokalp/char_rnn_rap_generator\n",
        "#and download the two files; lyrics_array_mix.pickle - under data folder.\n",
        "#After that run the below cell. \n",
        "#Then on the tab to the left of the screen there is a folder icon, \n",
        "#click that and youll see data folder\n",
        "#click upload and upload the files you downloaded. \n",
        "#Then drag them in the data folder\n",
        "#then you can continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sC-EpAcjSTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# DRIVE_PATH = '/content/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okZ3iyatVLre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_ROOT_DIR = \".\"\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\")\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = os.path.join(PROJECT_ROOT_DIR, \"saved_models\")\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "def save(fname, data, extension=\"pickle\"):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + extension)\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def load(fname, extension='pickle'):\n",
        "    path = os.path.join(DATA_PATH, fname + \".\" + extension)\n",
        "    \n",
        "    with open(path, 'rb') as f:\n",
        "        item = pickle.load(f)\n",
        "\n",
        "    return item"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47e_XqDIbCuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRAB TRAINING DATA:\n",
        "documents = load('lyrics_array_mix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxtv1YLAO5LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE NEW TRAINING DATA - IF YOU WANT\n",
        "\n",
        "import time\n",
        "!pip install lyricsgenius\n",
        "import lyricsgenius\n",
        "\n",
        "API_TOKEN = '1OWmIr37ZuUI5hDXjN_FIXJlbZadIqH6JBDObBCiF_MNySn4BQqh8aQ8OUYF5muk'\n",
        "fname = 'mix'\n",
        "\n",
        "#### grab the lyrics #####\n",
        "artists = []\n",
        "genius = lyricsgenius.Genius(API_TOKEN, skip_non_songs=True, remove_section_headers=True)\n",
        "\n",
        "# lonely = genius.search_artist(\"The Lonely Island\", max_songs=80, sort=\"popularity\")\n",
        "# artists.append(lonely)\n",
        "# time.sleep(30)\n",
        "\n",
        "fetty = genius.search_artist(\"Fetty Wap\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(fetty)\n",
        "childish = genius.search_artist(\"Childish Gambino\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(childish)\n",
        "time.sleep(10)\n",
        "\n",
        "drake = genius.search_artist(\"Drake\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(drake)\n",
        "kendrick = genius.search_artist(\"Kendrick Lamar\", max_songs=20, sort=\"popularity\")\n",
        "artists.append(kendrick)\n",
        "time.sleep(20)\n",
        "\n",
        "# drake = genius.search_artist(\"Lil Dicky\", max_songs=20, sort=\"popularity\")\n",
        "# artists.append(drake)\n",
        "chet = genius.search_artist(\"Chet Faker\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(chet)\n",
        "time.sleep(30)\n",
        "\n",
        "snoop = genius.search_artist(\"Snoop Dogg\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(snoop)\n",
        "travis = genius.search_artist(\"Travis Scott\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(travis)\n",
        "q = genius.search_artist(\"ScHoolboy Q\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(q)\n",
        "wayne = genius.search_artist(\"Lil Wayne\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(wayne)\n",
        "time.sleep(30)\n",
        "\n",
        "eminem = genius.search_artist(\"Eminem\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(eminem)\n",
        "ariana = genius.search_artist(\"Ariana Grande\", max_songs=5, sort=\"popularity\")\n",
        "artists.append(ariana)\n",
        "wiz = genius.search_artist(\"Wiz Khalifa\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(wiz)\n",
        "beatles = genius.search_artist(\"The Beatles\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(beatles)\n",
        "billie = genius.search_artist(\"Billie Eilish\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(billie)\n",
        "peas = genius.search_artist(\"Black Eyed Peas\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(peas)\n",
        "time.sleep(40)\n",
        "\n",
        "chance = genius.search_artist(\"Chance The Rapper\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(chance)\n",
        "kanye = genius.search_artist(\"Kanye West\", max_songs=15, sort=\"popularity\")\n",
        "artists.append(kanye)\n",
        "outkast = genius.search_artist(\"OutKast\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(outkast)\n",
        "rihanna = genius.search_artist(\"Rihanna\", max_songs=10, sort=\"popularity\")\n",
        "artists.append(rihanna)\n",
        "\n",
        "\n",
        "documents = []\n",
        "for artist in artists:\n",
        "  for song in artist.songs: \n",
        "    documents.append(song.lyrics)\n",
        "\n",
        "save('lyrics_array_' + fname, documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzBbUU-zdUuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COMBINE ALL SONGS INTO ONE TEXT FILE\n",
        "\n",
        "comedy_rap_text = ''\n",
        "for document in documents:\n",
        "  if document is not None:\n",
        "    comedy_rap_text += document + '\\n'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbFGKmYdt1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLEAN THE TEXT, GET RID OF SOME PATTERNS\n",
        "\n",
        "comedy_rap_prepped = comedy_rap_text\n",
        "import re\n",
        "pattern = re.compile(r'[(.?)]')\n",
        "comedy_rap_prepped = re.sub(pattern, '', comedy_rap_prepped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBROFg1RCZPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpu_info = !nvidia-smi\n",
        "# gpu_info = '\\n'.join(gpu_info)\n",
        "# if gpu_info.find('failed') >= 0:\n",
        "#   print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "#   print('and then re-execute this cell.')\n",
        "# else:\n",
        "#   print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-klkN5O-qh",
        "colab_type": "code",
        "outputId": "26773b77-d6a5-4b04-b582-d8ebd57615a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# PREPROCESSING THE TRAINING DATA SO THAT CHAR MODEL CAN USE\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(comedy_rap_prepped)\n",
        "max_id = len(tokenizer.word_index) \n",
        "dataset_size = tokenizer.document_count\n",
        "\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([comedy_rap_prepped])) - 1\n",
        "\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)\n",
        "\n",
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 89) (32, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9-upMafXBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.load_model(os.path.join(DRIVE_PATH, 'rap_bot_v2_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpAqCOljvoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IF YOU WANT TO TRAIN FROM SCRATCH - RNN NETWORK WITH DROPOUT\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As92lnnXTVKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "aafb964e-ac01-4df4-9afb-c5bbdd42d668"
      },
      "source": [
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=8)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "  252/22297 [..............................] - ETA: 1:53:05 - loss: 2.7200"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-762c6189a908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-7Fzn4f0cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO SAVE THE TRAINED NEW MODEL\n",
        "model.save('./saved_models/rap_bot_v3_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiVw2ecDHv2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HELPER FUNCTIONS FOR NEW LYRICS GENERATION\n",
        "\n",
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)\n",
        "\n",
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
        "\n",
        "\n",
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIfy092Hcn7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIS WILL GENERATE WARNINGS - JUST IGNORE\n",
        "# temperature param represents how the next word is sampled, close to 0 just does argmax, \n",
        "# around 1 worked good for me you can just try different and look at the results\n",
        "# to not to keep generating same things usually they dont do argmax over the probabilities instead you sample from them with the prob of the probabilities\n",
        "# n_chars - number of characters you want to generate\n",
        "tf.random.set_seed(42)\n",
        "text = complete_text(\"y\", temperature=1, n_chars=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Y1I6bAltfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !!!!! LETS SEEE :D\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1hY2qxiIs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}